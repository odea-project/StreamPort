{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.StreamPort.core as core\n",
    "\n",
    "anas = core.Analyses()\n",
    "pm = core.ProcessingMethod()\n",
    "mt = core.Metadata(description=\"test\", version=\"1.0\")\n",
    "wf = core.Workflow()\n",
    "\n",
    "print(anas)\n",
    "print(pm)\n",
    "print(mt)\n",
    "print(wf)\n",
    "\n",
    "core = core.Engine()\n",
    "core.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.StreamPort.core import Engine\n",
    "from src.StreamPort.core import Analyses\n",
    "\n",
    "print(\"1: Creates an Analyses object and prints it\")\n",
    "\n",
    "ana1 = Analyses(data_type=\"unknown\", formats=[], data = [\n",
    "  {\"name\": \"Analysis 1\", \"x\": np.arange(1, 11), \"y\": np.random.randint(0, 100, 10)},\n",
    "  {\"name\": \"Analysis 2\", \"x\": np.arange(1, 11), \"y\": np.random.randint(0, 100, 10)},\n",
    "  {\"name\": \"Analysis 3\", \"x\": np.arange(1, 11), \"y\": np.random.randint(0, 100, 10)},\n",
    "  {\"name\": \"Analysis 4\", \"x\": np.arange(1, 11), \"y\": np.random.randint(0, 100, 10)}\n",
    "])\n",
    "\n",
    "x = Engine(analyses=ana1)\n",
    "\n",
    "x.print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProcessingMethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.StreamPort.core import Engine\n",
    "from src.StreamPort.core import ProcessingMethod\n",
    "\n",
    "x = Engine()\n",
    "\n",
    "print(\"1: Creates a ProcessingMethod object and prints it\")\n",
    "mt = ProcessingMethod()\n",
    "print(mt)\n",
    "\n",
    "print(\"2: Adds the settings to the Engine\")\n",
    "x.workflow.append(mt)\n",
    "x.workflow.append(mt)\n",
    "print(\"Number of methods: \", len(x.workflow))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"3: Removes the settings from the Engine\")\n",
    "x.workflow.pop(1)\n",
    "print(\"Number of methods: \", len(x.workflow))\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProcessingMethod dispatchment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.StreamPort.core import Engine\n",
    "from src.StreamPort.core import ProcessingMethod\n",
    "from src.StreamPort.core import Analyses\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class UnkownNormalizeMinMax(ProcessingMethod):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.data_type = \"unknown\"\n",
    "        self.method = \"Normalize\"\n",
    "        self.algorithm = \"MinMax\"\n",
    "        self.input_instance = dict\n",
    "        self.output_instance = dict\n",
    "        self.number_permitted = float(\"inf\")\n",
    "\n",
    "    def run(self, analyses):\n",
    "        res = analyses.data\n",
    "        if len(res) > 0:\n",
    "            for i in range(len(res)):\n",
    "                ana = res[i]\n",
    "                if not isinstance(ana, dict) or \"y\" not in ana:\n",
    "                    print(\n",
    "                        f\"Skipping {ana['name']} because its data is not a dictionary with a 'y' key.\"\n",
    "                    )\n",
    "                    continue\n",
    "                ana[\"y\"] = (ana[\"y\"] - ana[\"y\"].min()) / (ana[\"y\"].max() - ana[\"y\"].min())\n",
    "                res[i] = ana\n",
    "            analyses.data = res\n",
    "        else:\n",
    "            print(\"No data to process.\")\n",
    "        return analyses\n",
    "\n",
    "\n",
    "# Algorithm specific class\n",
    "class UnkownNormalizeSNV(ProcessingMethod):\n",
    "    def __init__(self, liftToZero=True):\n",
    "        super().__init__()\n",
    "        self.data_type = \"unknown\"\n",
    "        self.method = \"Normalize\"\n",
    "        self.algorithm = \"standard_variance_normalization\"\n",
    "        self.input_instance = dict\n",
    "        self.output_instance = dict\n",
    "        self.number_permitted = float(\"inf\")\n",
    "        self.parameters = {\"liftToZero\": liftToZero}\n",
    "\n",
    "    def run(self, analyses):\n",
    "        res = analyses.data\n",
    "        if len(res) > 0:\n",
    "            for i in range(len(res)):\n",
    "                ana = res[i]\n",
    "                if not isinstance(ana, dict) or \"y\" not in ana:\n",
    "                    print(\n",
    "                        f\"Skipping {ana['name']} because its data is not a dictionary with a 'y' key.\"\n",
    "                    )\n",
    "                    continue\n",
    "                y = np.array(ana[\"y\"])\n",
    "                norm_data = (y - y.mean()) / y.std()\n",
    "                if self.parameters[\"liftToZero\"]:\n",
    "                    norm_data += abs(norm_data.min())\n",
    "                ana[\"y\"] = norm_data\n",
    "                res[i] = ana\n",
    "            analyses.data = res\n",
    "        else:\n",
    "            print(\"No data to process.\")\n",
    "        return analyses\n",
    "\n",
    "anas = Analyses(data_type=\"unknown\", formats=[], data = [\n",
    "  {\"name\": \"Analysis 1\", \"x\": np.arange(1, 11), \"y\": np.random.randint(0, 100, 10)},\n",
    "  {\"name\": \"Analysis 2\", \"x\": np.arange(1, 11), \"y\": np.random.randint(0, 100, 10)},\n",
    "  {\"name\": \"Analysis 3\", \"x\": np.arange(1, 11), \"y\": np.random.randint(0, 100, 10)},\n",
    "  {\"name\": \"Analysis 4\", \"x\": np.arange(1, 11), \"y\": np.random.randint(0, 100, 10)}\n",
    "])\n",
    "\n",
    "x = Engine(analyses=anas)\n",
    "\n",
    "print(\"1: Prints the analyses results in the Engine\")\n",
    "for res in x.analyses.data:\n",
    "    print(f\"Analyses: {res[\"name\"]}\")\n",
    "    print(f\"{\"x\"}: {res[\"x\"]}\")\n",
    "    print(f\"{\"y\"}: {res[\"y\"]}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Create an instance of the UnknownNormalizeMinMax class\n",
    "norm_method = UnkownNormalizeMinMax()\n",
    "\n",
    "# Create an instance of the UnknownNormalizeSNV class\n",
    "norm_method2 = UnkownNormalizeSNV()\n",
    "\n",
    "# Run the settings MinMax using the analyses as argument\n",
    "analyses_minmax = norm_method.run(x.analyses)\n",
    "\n",
    "print(\"2: Results from settings MinMax\")\n",
    "for key in analyses_minmax.data:\n",
    "    print(f\"Analyses: {key['name']}\")\n",
    "    print(f\"x: {key['x']}\")\n",
    "    print(f\"y: {key['y']}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Run the settings SNV using the engine as argument\n",
    "analyses_svn = norm_method2.run(x.analyses)\n",
    "\n",
    "print(\"3: Results from settings snv\")\n",
    "for key in analyses_svn.data:\n",
    "    print(f\"Analyses: {key['name']}\")\n",
    "    print(f\"x: {key['x']}\")\n",
    "    print(f\"y: {key['y']}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Adds method to the Engine\n",
    "x.workflow.append(norm_method)\n",
    "\n",
    "x.print()\n",
    "\n",
    "x.run()\n",
    "\n",
    "print(\"4: Results from the engine\")\n",
    "for key in x.analyses.data:\n",
    "    print(f\"Analyses: {key['name']}\")\n",
    "    print(f\"x: {key['x']}\")\n",
    "    print(f\"y: {key['y']}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Inheritance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Person:\n",
    "  \"\"\"Class docstrings go here.\"\"\"\n",
    "\n",
    "  def __init__(self, fname, lname):\n",
    "    self.firstname = fname\n",
    "    self.lastname = lname\n",
    "\n",
    "  def printname(self):\n",
    "    \"\"\"Class method docstrings go here.\"\"\"\n",
    "    print(self.firstname, self.lastname)\n",
    "\n",
    "  def welcome_from_parent(self):\n",
    "    print(\"Welcome from parent class\")\n",
    "\n",
    "#Use the Person class to create an object, and then execute the printname method:\n",
    "\n",
    "x = Person(\"John\", \"Doe\")\n",
    "\n",
    "x.printname()\n",
    "\n",
    "class Student(Person):\n",
    "  def __init__(self, fname, lname, year):\n",
    "    super().__init__(fname, lname)\n",
    "    self.graduationyear = year\n",
    "\n",
    "  def welcome(self):\n",
    "    print(\"Welcome\", self.firstname, self.lastname, \"to the class of\", self.graduationyear)\n",
    "\n",
    "  def printname(self):\n",
    "    print(self.firstname, self.lastname, \"overwritten!\")\n",
    "\n",
    "  def printname_from_parent(self):\n",
    "    super().printname()\n",
    "\n",
    "x = Student(\"Mike\", \"Olsen\", 2019)\n",
    "\n",
    "x.printname()\n",
    "\n",
    "x.printname_from_parent()\n",
    "\n",
    "x.welcome()\n",
    "\n",
    "x.welcome_from_parent()\n",
    "\n",
    "#help(Person)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
