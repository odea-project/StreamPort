{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeviceEngine Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dedicated engine for device data, inherited from Core Engine. Each DeviceEngine class object will represent a unique device with its own set of processing parameters and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.StreamPort.device.DeviceEngine import DeviceEngine\n",
    "from src.StreamPort.core.ProjectHeaders import ProjectHeaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify path to get analyses from\n",
    "base_dir = r'C:\\Users\\PC0118\\Desktop\\ExtractedSignals'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates an empty DeviceEngine object and prints it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dev = DeviceEngine(source = base_dir)\n",
    "dev.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeviceEngine object without an explicitly provided source performs all capabilities on files within the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev1 = DeviceEngine()\n",
    "dev1.print()\n",
    "print(dev1._source)\n",
    "del dev1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProjectHeaders Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add project headers. They can be passed as ProjectHeaders objects or dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.add_headers(headers = {'name': 'Pressure Curve Analysis', 'author': 'Sandeep H.'})\n",
    "dev.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeviceAnalysis Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each DeviceAnalysis object is a child of the Analysis Class. It holds the details of an Analysis for each individual device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.StreamPort.device.DeviceAnalysis import DeviceAnalysis\n",
    "\n",
    "#Creates an empty DeviceAnalysis object and prints it\n",
    "devAnalysis = DeviceAnalysis()\n",
    "devAnalysis.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "DeviceEngine's find_analyses() method returns a DeviceAnalysis Object or a list of DeviceAnalysis objects, besides printing the dataframes for each unique Method, paired with the metadata(Date, Runtime) for each curve.\n",
    "\n",
    "This method makes use of the source variable to accept a path to a directory containing analyses as an argument and find analyses from the target path.\n",
    "\n",
    "The path can refer to a directory containing data for specific groups of experiments \"210812_Gem 2021-08-12 09-49-10\" or one such experiment containing its own set of method-related analysis data \"210812_Gem--005.D\", \"210812_Gem--007.D\", ..\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read analysis objects from engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyses = dev.find_analyses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each DeviceEngine object has an attribute _method_ids that records all methods encountered in the analysis of the current Device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dev._method_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And an attribute _history to hold data on all experiments related to this device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add analyses objects that were found using find_analyses() to current device records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add analyses in the form of individual DeviceAnalysis objects or a list of such objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.add_analyses(analyses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ana in dev._analyses:\n",
    "    print(\"\\n\")\n",
    "    print(\"Analysis Object : \\n\")\n",
    "    print(f\"Analysis : {ana.print()}\")\n",
    "    print(\"Data of Analysis : \\n\")\n",
    "    print(ana.data)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeviceEngine's *plot_analyses()* and *plot_results()* calls each analysis object's respective *plot()* function after dynamically grouping related analyses. \n",
    "Grouping is done on the basis of unique method id's paired with unique experiment dates.\n",
    "User can set the 'group_by'(str) argument to control how the data is grouped. Defaults to 'method', otherwise 'date'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot analyses by calling inbuilt plot function and passing each object's index as argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot analyses by word or subword present in analysis date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.plot_analyses('Pac', group_by='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot all available analyses by omitting 'analyses' argument\n",
    "Group by defaults to 'method'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.plot_analyses('Gem', group_by='method')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProcessingSettings - Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new ProcessingSettings object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.StreamPort.device.DeviceProcSettings import ExtractPressureFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'weighted' argument of ExtractPressureFeatures object can be used to control whether the pressure curves should first be transformed by calculating percentage change between adjacent datapoints.\n",
    "Defaults to False, in which case feature extraction is performed on the raw pressure curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = ExtractPressureFeatures(weighted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add processing settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.add_settings(settings)\n",
    "dev.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the settings to extract pressure features after adding analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressure_features = settings.run(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pressure_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the extracted features to the results (dict) attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.add_results(pressure_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the stored results associated with the current object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProcessingSettings - Seasonal Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new ProcessingSettings object to extract seasonal components from analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.StreamPort.device.DeviceProcSettings import DecomposeCurves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*'period' argument of DecomposeCurves is used to control the window size over which the features are calculated. Defaults to 30 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_decompose = DecomposeCurves(period=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.add_settings(curve_decompose)\n",
    "dev.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_components = curve_decompose.run(dev)\n",
    "print(seasonal_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.add_results(seasonal_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.get_results(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Each .D folder is an analysis with timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latest entry in analyses contains most up to date results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProcessingSettings - Fourier Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new ProcessingSettings object to perform Fast Fourier Analysis on raw curve and seasonal component of analyses time decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.StreamPort.device.DeviceProcSettings import FourierTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourier_transform = FourierTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.add_settings(fourier_transform)\n",
    "dev.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_seasonal = fourier_transform.run(dev)\n",
    "print(transformed_seasonal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.add_results(transformed_seasonal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.get_results(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scaled results are unavailable since data has not been scaled yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding features before scaling:\n",
    "scale_features() calls add_extracted_features() before grouping and scaling data.\n",
    "\n",
    "add_extracted_features() introduces new features that were extracted from the behaviour of the seasonal and noise components of the raw curves in the frequency domain. These frequencies were binned and averaged in different time-windows and added as features.\n",
    "\n",
    "Additional features added were Idle time of the batch, error in defined vs. measured runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProcessingSettings - Feature Scaling  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale extracted and engineered features to improve the quality of the information we get from them. These prove more useful when visually analysing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.StreamPort.device.DeviceProcSettings import Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User selects the type of scaler to be used from preloaded options : 'minmax', 'std'(Standard), 'robust', 'maxabs', 'norm'(Normalizer).\n",
    "Scaler defualts to Normalizer in the absence of an argument.\n",
    "\n",
    "'replace' argument allows user to replace existing features with scaled features or to create a new entry instead. Defaults to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scaler = Scaler(parameters='std')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.add_settings(feature_scaler)\n",
    "dev.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features = feature_scaler.run(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.add_results(scaled_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the computed results of feature extraction for chosen results based on user input to select *base* to extract base features, *decompose* for seasonal decomposition, fourier *transform* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User may also plot the raw pressure curves by omitting the 'features' argument, indicating that the *results* of feature extraction are not to be plotted, just the curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this_method = dev._method_ids[6]\n",
    "this_method = 'Pac' \n",
    "print(this_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'group_by' allows user to group data either by 'date' or 'method':\n",
    "1. 'date' prepares data with weight on experiment date. So matching methods on different dates will not be grouped.\n",
    "2. 'method' prepares data purely on method and groups all available data for the given method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.plot_results(this_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select features to plot. Setting 'scaled' argument allows to toggle plots of scaled features or unscaled. Defaults to True.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.plot_results(results = this_method, features ='base', scaled=True, transpose=True, group_by='method', interactive=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.plot_results(results = this_method, features ='base', transpose=False, interactive=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use 'interactive' argument to toggle between static and interactive plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "setting type to 'box' enables a box plot of the data. Available options are 'box' and 'scatter' by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.plot_results(results = this_method, features ='transform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MachineLearning - Isolation Forest for preliminary classification  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADD CLASS LABELS TO ANALYSIS OBJECTS AFTER FEATURE ANALYSIS. FIRST ANALYSIS '001-blank' is assigned a separate class of ML operations due to it being a systematic fault."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classify() dynamically assigns class labels through MLEngine's make_iso_forest() to all analyses encountered and classified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a MachineLearningEngine object to enable ML ops on prepared data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.StreamPort.ml.MachineLearningEngine import MachineLearningEngine\n",
    "from src.StreamPort.ml.MachineLearningAnalysis import MachineLearningAnalysis\n",
    "from src.StreamPort.ml.MachineLearningProcessingSettings import MakeModelIsoForest\n",
    "from src.StreamPort.ml.MachineLearningProcessingSettings import MakeModelPCASKL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_engine = MachineLearningEngine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random_state(int) argument can be specified to reproduce results. Defaults to None, sets a random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_forest = MakeModelIsoForest(dev, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_engine.add_settings(iso_forest)\n",
    "ml_engine.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_objects = iso_forest.run(ml_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MachineLearning - PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make_iso_forest() of MLEngine class automatically creates sub-objects of MLEngine class for each encountered group of analyses per unique method after performing iso_forest and plotting results. Can be modified to save results later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = MakeModelPCASKL(n_components = 2, center_data= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "for obj in method_objects:\n",
    "    obj.add_settings(pca)\n",
    "    obj.print()\n",
    "    pca_scores = pca.run(obj)\n",
    "    obj.add_results(pca_scores)\n",
    "    obj.plot_pca()\n",
    "    \n",
    "    webbrowser.open('pca_scores_plot.html')\n",
    "    webbrowser.open('pca_loadings_plot.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce everything here on Orange and then try 26k data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML file manipulation for real-time classification and maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Future implementation will allow to scan for actuals in a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_file = r'C:\\Users\\PC0118\\Desktop\\Chemstation Actuals\\actuals 9.8.2024 10_18_9-943.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(xml_file)\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traverse from root to end nodes and find relevant status information to build a dataframe out of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#second child of root contains actuals, first child holds schematics for data\n",
    "print(root[0].tag, root[0].attrib)\n",
    "diffgrams = root[1]\n",
    "print(len(diffgrams))\n",
    "print(diffgrams.tag, diffgrams.attrib, diffgrams.text)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "#dataframe to hold data in xml file initiated with list of entries and sample names identified by timestamp \n",
    "diffgram_df = pd.DataFrame()\n",
    "samples = []\n",
    "\n",
    "feature = []\n",
    "\n",
    "num_observations = len(diffgrams[0])\n",
    "print('Observations', num_observations)\n",
    "\n",
    "for element in diffgrams[0]:\n",
    "        print(element.tag, element.attrib, element[0].text)\n",
    "\n",
    "        if element[0].text in samples:\n",
    "                feature = pd.DataFrame(feature, index=[f'Analysis - {sample}' for sample in samples])\n",
    "                diffgram_df = pd.concat([diffgram_df, feature], axis = 1)\n",
    "                feature = []\n",
    "                samples = []\n",
    "        feature.append({element.tag : element.get('{urn:schemas-microsoft-com:xml-diffgram-v1}id')})\n",
    "        samples.append(element[0].text)\n",
    "if feature != [] or samples != []:\n",
    "        feature = pd.DataFrame(feature, index=[f'Analysis - {sample}' for sample in samples])\n",
    "        diffgram_df = pd.concat([diffgram_df, feature], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diffgram_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#packages to create a dashboard\n",
    "import dash\n",
    "from dash import dcc\n",
    "from dash import html \n",
    "from dash.dependencies import Input, Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up divisions with the option to select the information to be displayed\n",
    "\n",
    "# something off here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = dash.Dash(__name__)\n",
    "app.layout =html.Div([\n",
    "\n",
    "                        html.Div([  \n",
    "                        html.H1('Title', style={'text-align' : 'center'}),\n",
    "\n",
    "\n",
    "                        dcc.RadioItems(\n",
    "                                        id='radio-items',\n",
    "                                        options=[\n",
    "                                                    {'label' : 'Curves', 'value' : ''},\n",
    "                                                    {'label' : 'Features', 'value' : 'base'},\n",
    "                                                    {'label' : 'Decomp', 'value' : 'decompose'},\n",
    "                                                    {'label' : 'Transform', 'value' : 'transform'}\n",
    "                                                ],\n",
    "                                        value=''   #default\n",
    "                                       ),\n",
    "                                       html.Div(id='output-container',\n",
    "                                                style={\n",
    "                                                    'backgroundColor': '#f9f9f9',\n",
    "                                                    'border': '1px solid #ccc',\n",
    "                                                    'padding': '20px',\n",
    "                                                    'borderRadius': '5px',\n",
    "                                                    'boxShadow': '2px 2px 12px rgba(0, 0, 0, 0.1)'\n",
    "                                                    }\n",
    "                                                )\n",
    "                                ]),\n",
    "\n",
    "                        html.Div([\n",
    "                        dcc.DatePickerRange(\n",
    "                            id='date-picker-range',\n",
    "                            start_date='2023-01-01',\n",
    "                            end_date='2023-12-31',\n",
    "                            display_format='YYYY-MM-DD'\n",
    "                        )\n",
    "                        ], style={'border': '1px solid black', 'padding': '10px', 'margin': '10px'})\n",
    "\n",
    "                    ]) \n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import webbrowser\n",
    "@app.callback(    \n",
    "    Output('output-container', 'children'),\n",
    "    Input('radio-items', 'value')\n",
    ")\n",
    "def update_graph(value):\n",
    "    dev.plot_results('Pac', features=value)\n",
    "    #webbrowser.open('plot.html')\n",
    "    return     \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
