{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5a2253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run extract.bat \"Path\\to\\SignalExtraction\\Tool\" \"Path\\to\\method_data\\root_directory\" to automate SignalExtraction. \n",
    "\n",
    "# this takes a while and provides output only once complete or interrupted, unless the subprocess library is used to capture the shell output in real time\n",
    "#!src\\StreamPort\\extract.bat \"C:\\Users\\Sandeep\\Desktop\\SignalExtraction v.01\" \"C:\\Users\\Sandeep\\Desktop\\Error-LC\\Method-Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226388a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.StreamPort.device.analyses import PressureCurvesAnalyses\n",
    "\n",
    "path = \"C:/Users/Sandeep/Desktop/Error-LC/Method-Data\"\n",
    "batches = os.listdir(path)\n",
    "batches = [os.path.join(path, file) for file in batches]\n",
    "\n",
    "error_lc_files = []\n",
    "for batch in batches:\n",
    "    batch_files = os.listdir(batch)\n",
    "    batch_files = [os.path.join(batch, file) for file in batch_files if \".D\" in file]\n",
    "    error_lc_files.extend(batch_files)\n",
    "\n",
    "#%store error_lc_files    \n",
    "analyses = PressureCurvesAnalyses(files=error_lc_files)\n",
    "print(\"Number of analyses: \", len(analyses.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ced24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error_lc curves belong to the same method\n",
    "batches = analyses.get_batches()\n",
    "batch_plot = analyses.plot_batches()\n",
    "batch_plot.show()\n",
    "print(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4717ac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "batch_list = pd.read_excel(\"C:/Users/Sandeep/Desktop/Error-LC/Batch-Liste.xlsx\")\n",
    "batch_list.head()\n",
    "\n",
    "bad_batch_ids = batch_list[\"provoked_error\"] != None\n",
    "bad_batches = batch_list.loc[bad_batch_ids, \"batch_name\"]\n",
    "print(bad_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d860f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_indices = []\n",
    "for i in batches:\n",
    "    indices = analyses.get_batch_indices(i)\n",
    "    print(\"batch: \", i,\" indices: \", indices)\n",
    "    batch_indices.extend(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942ce980",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of curves: \", len(batch_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03006f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = analyses.get_batch_indices('250613_Mix-1_10x10ng-mL 2025-06-13 14-40-12') + (analyses.get_batch_indices('250613_Mix-1_10x100ng-mL 2025-06-13 17-02-43')) + (analyses.get_batch_indices('250616_Mix-1_50x100ng-mL 2025-06-16 10-06-17')) + (analyses.get_batch_indices('250623_Mix-1_25x100ng-mL 2025-06-23 15-57-58')) + (analyses.get_batch_indices('250624_Mix-1_20x100ng-mL 2025-06-24 16-17-42')) + (analyses.get_batch_indices('250626_Mix-1_50x100ng-mL 2025-06-26 09-05-34')) + (analyses.get_batch_indices('250702_Mix-1+IS_50x100ng-mL 2025-07-02 09-46-06')) + (analyses.get_batch_indices('250707_Mix-1+IS_30x100ng-mL 2025-07-07 14-47-33'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d627e764",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_train_curves_raw = analyses.plot_pressure_curves(analyses.get_batch_indices(\"250624_Mix-1_20x100ng-mL 2025-06-24 16-17-42\")+ (analyses.get_batch_indices(\"250624_Mix-1_30x100ng-mL 2025-06-24 10-33-02\")) + analyses.get_batch_indices(\"250623_Mix-1_25x100ng-mL 2025-06-23 15-57-58\"))#train_batch[ : len(train_batch)//2])\n",
    "\n",
    "for trace in fig_train_curves_raw.data:\n",
    "    trace.line.color = \"black\"\n",
    "\n",
    "fig_train_curves_raw.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba595593",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [612, 613, 616, 366, 367, 369, 368, 31, 615, 614, 16, 0, 1, 13, 15]:\n",
    "    if i in train_batch:\n",
    "        train_batch.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31dd843",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(189, 217):\n",
    "    if i in train_batch:\n",
    "        train_batch.remove(i)\n",
    "for j in range(222, 288):\n",
    "    if j in train_batch:\n",
    "        train_batch.remove(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5aaa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = list(set(batch_indices) - set(train_batch))\n",
    "print(\"Train: \", len(train_batch), \" \", train_batch)\n",
    "print(\"Test: \", len(test_batch), \" \", (test_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca918ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_train_curves = analyses.plot_pressure_curves(train_batch)\n",
    "fig_train_curves.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab85aeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import datetime\n",
    "\n",
    "train_set = random.sample(train_batch, random.randint(20, 35))\n",
    "print(\"Train set: \", len(train_set), \" curves - \", train_set)\n",
    "test_dates = []\n",
    "\n",
    "for i in [1, 2, 3]:\n",
    "    now = datetime.datetime.now().isoformat()\n",
    "    now = now.replace(\":\", \"-\").replace(\".\", \"-\").replace(\"T\", \" \")\n",
    "\n",
    "    test_set = random.sample(test_batch, len(train_set)//3)#take ~25-35% of train data size for test data\n",
    "    test_dates.append({now : test_set})\n",
    "    print(\"Test set \", now ,  \" indices: \", test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2dcc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_train_curves_raw = analyses.plot_pressure_curves(train_set)\n",
    "\n",
    "for trace in fig_train_curves_raw.data:\n",
    "    trace.line.color = \"black\"\n",
    "\n",
    "fig_train_curves_raw.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebb0d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.StreamPort.device.methods import PressureCurvesMethodExtractFeaturesNative\n",
    "\n",
    "processor = PressureCurvesMethodExtractFeaturesNative(window_size=random.randint(3, 11), bins=random.randint(3, 8)) # defaults: (period = 10, window_size = 7, bins = 4, crop = 2)\n",
    "processor.run(analyses)\n",
    "parameters = processor.parameters\n",
    "print(\"Feature extraction parameters: \", parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c7b6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_features=analyses.plot_features(indices = train_set)\n",
    "\n",
    "for trace in fig_features.data:\n",
    "    trace.line.color = \"black\"\n",
    "\n",
    "fig_features.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d37f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = analyses.get_features(train_set)\n",
    "train_metadata = analyses.get_metadata(train_set)\n",
    "train_data.to_csv(\"dev/error_lc_train_features.csv\", index=False)\n",
    "train_metadata.to_csv(\"dev/error_lc_train_metadata.csv\", index=False)\n",
    "print(\"Number of training curves: \", len(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8db4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.StreamPort.machine_learning.analyses import MachineLearningAnalyses\n",
    "\n",
    "iso_analyses = MachineLearningAnalyses(variables = train_data, metadata = train_metadata)\n",
    "print(iso_analyses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2079f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.StreamPort.machine_learning.methods import MachineLearningScaleFeaturesScalerSklearn \n",
    "\n",
    "scl = MachineLearningScaleFeaturesScalerSklearn(scaler_type=random.choice([\"RobustScaler\", \"MaxAbsScaler\", \"MaxNormalizer\", \"StandardScaler\", \"MinMaxScaler\"]))\n",
    "scaling_parameters = scl.parameters\n",
    "print(\"Scaling parameters: \", scaling_parameters)\n",
    "parameters.update(scaling_parameters)\n",
    "\n",
    "iso_analyses = scl.run(iso_analyses)\n",
    "fig_train_features = iso_analyses.plot_data()\n",
    "fig_train_features.update_layout(title=\"Train set features\")\n",
    "fig_train_features.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08de9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.StreamPort.machine_learning.methods import MachineLearningMethodIsolationForestSklearn\n",
    "\n",
    "iso = MachineLearningMethodIsolationForestSklearn()#force determinism to explain feature importance or for clean model generalization\n",
    "iforest_parameters = iso.parameters\n",
    "print(\"Isolation Forest parameters: \", iforest_parameters)\n",
    "parameters.update(iforest_parameters)\n",
    "\n",
    "iso_analyses = iso.run(iso_analyses)\n",
    "iso_analyses.train()\n",
    "fig_train_scores = iso_analyses.plot_scores()\n",
    "fig_train_scores.show()\n",
    "\n",
    "parameters_df = []\n",
    "\n",
    "for test in test_dates:\n",
    "    date = list(test.keys())[0]\n",
    "    test_set = list(test.values())[0]\n",
    "\n",
    "    test_data = analyses.get_features(test_set)\n",
    "    test_metadata = analyses.get_metadata(test_set)\n",
    "    test_data.to_csv(f\"dev/error_lc_test_{date}_features.csv\", index=False)\n",
    "    test_metadata.to_csv(f\"dev/error_lc_test_{date}_metadata.csv\", index=False)\n",
    "\n",
    "    fig_test_curves=analyses.plot_pressure_curves(indices = test_set)\n",
    "    fig_test_curves.update_layout(showlegend=False)\n",
    "    fig_test_curves.write_image(f\"dev/figures/fig_error_lc_test_{date}_curves.png\", width=1000, height= 350, scale = 3)\n",
    "    #fig_test_curves.show()\n",
    "\n",
    "    fig_test_features=analyses.plot_features(indices = test_set)\n",
    "    fig_test_features.update_layout(showlegend=False)\n",
    "    fig_test_features.write_image(f\"dev/figures/fig_error_lc_test_{date}_features.png\", width=1100, height= 350, scale = 3)\n",
    "    fig_test_features.show()\n",
    "    \n",
    "    fig_test_features_raw = analyses.plot_features_raw(indices = test_set)\n",
    "    fig_test_features_raw.update_layout(showlegend=False)\n",
    "    fig_test_features_raw.write_image(f\"dev/figures/fig_error_lc_test_{date}_features_raw.png\", width=1100, height= 350, scale = 3)\n",
    "    fig_test_features_raw.show()\n",
    "\n",
    "\n",
    "\n",
    "    iso_analyses.predict(test_data, test_metadata)\n",
    "    outliers_test = iso_analyses.test_prediction_outliers()\n",
    "\n",
    "    classified_test_metadata = outliers_test\n",
    "    classified_test_metadata[\"date\"] = date\n",
    "\n",
    "    print(\"Test set \", i, \": \\n\", test_metadata[\"index\"].tolist()) \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    test_batch_parameters = parameters.copy()\n",
    "    test_size = len(test_metadata)\n",
    "\n",
    "    train_scores = iso_analyses.get_training_scores()\n",
    "    train_size = len(train_scores)\n",
    "\n",
    "    threshold = classified_test_metadata[\"threshold\"].iloc[0]\n",
    "    num_outliers = sum(classified_test_metadata[\"class\"] == \"outlier\")\n",
    "    percent_outliers = (sum(classified_test_metadata[\"class\"] == \"outlier\")/len(classified_test_metadata[\"class\"]))*100\n",
    "\n",
    "    fig_test_scores = iso_analyses.plot_scores()\n",
    "    fig_test_scores.write_image(f\"dev/figures/fig_error_lc_test_{date}_scores.png\", width=1100, height= 350, scale = 3)\n",
    "    fig_test_scores.update_layout(title=f\"Test set {date[:19].replace(\"T\", \" \")}\")\n",
    "    fig_test_scores.show()\n",
    "\n",
    "    fig_test_features = iso_analyses.plot_data()\n",
    "    fig_test_features.write_image(f\"dev/figures/fig_error_lc_test_{date}_features.png\", width=1100, height= 350, scale = 3)\n",
    "    #fig_test_features.show()\n",
    "\n",
    "    #optionally add seen normal curves to train set\n",
    "    #iso_analyses.add_prediction()\n",
    "\n",
    "    # if num_outliers < 1:\n",
    "    #     threshold += 0.5*np.std(train_scores)\n",
    "\n",
    "    test_batch_parameters.update(\n",
    "        {\n",
    "        \"date\" : date,\n",
    "        \"train_set\" : train_size, \n",
    "        \"test_set\" : test_size,\n",
    "        \"threshold\" : threshold,\n",
    "        \"outliers\" : num_outliers,\n",
    "        \"outliers_percent\" : percent_outliers\n",
    "        }\n",
    "    )\n",
    "    parameters_df.append(test_batch_parameters)\n",
    "    classified_test_metadata.to_csv(f\"dev/error_lc_test_{date}_classified_samples.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d086aa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parameters_df = pd.DataFrame(parameters_df)\n",
    "if os.path.exists(\"dev/error_lc_test_record.csv\"):\n",
    "    old_records = pd.read_csv(\"dev/error_lc_test_record.csv\")\n",
    "    parameters_df = pd.concat([old_records, parameters_df])\n",
    "    parameters_df.drop_duplicates(subset=[\"date\"], keep=\"last\", inplace=True)\n",
    "    \n",
    "parameters_df.to_csv(\"dev/error_lc_test_record.csv\", index = False)\n",
    "print(\"Workflow parameters: \\n\", parameters_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb3885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "test_record = pd.read_csv(\"dev/error_lc_test_record.csv\") if os.path.exists(\"dev/error_lc_test_record.csv\") else None\n",
    "test_record = test_record.sort_values(\"date\")\n",
    "\n",
    "if test_record is not None:\n",
    "    result_logs = []\n",
    "    for date in test_record[\"date\"]:\n",
    "        result_logs.append(f\"dev/error_lc_test_{date}_classified_samples.csv\") if os.path.exists(f\"dev/error_lc_test_{date}_classified_samples.csv\") else print(f\"No records for {date}\")\n",
    "    \n",
    "    result_logs = [pd.read_csv(log) for log in result_logs]\n",
    "\n",
    "    for log in result_logs:\n",
    "        log[\"date\"] = log[\"date\"].astype(str).str[:19].str.replace(\"T\", \" \")\n",
    "\n",
    "    result_logs = [log.to_string(index=False).replace(\"\\n\", \"<br>\") for log in result_logs]\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=test_record[\"date\"],\n",
    "            y=test_record[\"threshold\"],\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"Threshold\",\n",
    "            yaxis=\"y1\",  \n",
    "            hovertemplate=[\n",
    "                \"<br>Threshold: \" + str(test_record[\"threshold\"][i])  \n",
    "                for i in range(len(test_record))\n",
    "            ],\n",
    "            line=dict(color=\"red\", width=2, dash='dash'),\n",
    "            marker=dict(size=8, symbol=\"circle\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=test_record[\"date\"],\n",
    "            y=test_record[\"outliers\"],\n",
    "            name=\"Outliers\",\n",
    "            yaxis=\"y2\",\n",
    "            width = 0.15, #width\n",
    "            marker_color=\"blue\",\n",
    "            hovertext=result_logs,\n",
    "            hoverinfo=\"text\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # fig.add_trace(\n",
    "    #     go.Scatter(\n",
    "    #         x=test_record[\"date\"],\n",
    "    #         y=test_record[\"outliers\"],\n",
    "    #         mode=\"lines+markers\",\n",
    "    #         name=\"Outliers\",\n",
    "    #         yaxis=\"y2\",\n",
    "    #         line=dict(color=\"blue\", width=2),\n",
    "    #         marker=dict(size=8, symbol=\"diamond\", color=\"blue\"),\n",
    "    #         hovertemplate=[\n",
    "    #             \"<br>Train Set: \" + str(test_record[\"train_set\"][i]) +\n",
    "    #             \"<br>Test Set: \" + str(test_record[\"test_set\"][i]) +\n",
    "    #             \"<br>Outliers: \" + str(test_record[\"outliers\"][i])\n",
    "    #             for i in range(len(test_record))\n",
    "    #         ]\n",
    "    #     )\n",
    "    # )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=test_record[\"date\"],\n",
    "            y=test_record[\"train_set\"], \n",
    "            mode=\"lines+markers\",\n",
    "            name=\"Training curves\",\n",
    "            yaxis=\"y2\",\n",
    "            hovertemplate=[\n",
    "                \"<br>Training samples: \" + str(test_record[\"train_set\"][i]) +\n",
    "                \"<br>Test samples: \" + str(test_record[\"test_set\"][i]) +\n",
    "                \"<br>Outliers: \" + str(test_record[\"outliers\"][i]) +\n",
    "                \"<br>Outliers %: \" + str(test_record[\"outliers_percent\"][i]) \n",
    "                for i in range(len(test_record))\n",
    "            ],\n",
    "            line=dict(color=\"green\", width=2, dash='solid'),\n",
    "            marker=dict(size=8, symbol=\"star\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Detection accuracy over Test Runs and Training Set Size\",\n",
    "    xaxis=dict(\n",
    "        tickvals=test_record[\"date\"], \n",
    "        ticktext=[d[:19].replace(\"T\", \" \") for d in test_record[\"date\"]], \n",
    "        tickangle=45,\n",
    "        title=\"Test Dates\"\n",
    "    ),\n",
    "    yaxis=dict(  \n",
    "        title=dict(text=\"Threshold\", font=dict(color=\"red\")),\n",
    "        tickfont=dict(color=\"red\")\n",
    "    ),\n",
    "    yaxis2=dict(#train set and outlier realistic in scale. Uncomment y3 to adjust \n",
    "        title=dict(text=\"Outliers\", font=dict(color=\"blue\")),\n",
    "        tickfont=dict(color=\"blue\"),\n",
    "        overlaying=\"y\",\n",
    "        side=\"right\"\n",
    "    ),\n",
    "    bargap = 1, \n",
    "    template=\"simple_white\",\n",
    "    legend=dict(\n",
    "        x=0.5,\n",
    "        y=1.1,\n",
    "        xanchor=\"center\",\n",
    "        yanchor=\"top\",\n",
    "        orientation=\"h\",  \n",
    "        bgcolor=\"rgba(255,255,255,0.5)\", \n",
    "        borderwidth=1  \n",
    "    )\n",
    ")\n",
    "fig.write_image(\"dev/figures/fig_error_lc_threshold_variation.png\", width=1100, height= 350, scale= 3)\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
