{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5a2253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run extract.bat \"Path\\to\\SignalExtraction\\Tool\" \"Path\\to\\method_data\\root_directory\" to automate SignalExtraction for processing. \n",
    "\n",
    "# this takes a while and provides output only once complete or interrupted, unless the subprocess library is used to capture the shell output in real time\n",
    "#!src\\StreamPort\\extract.bat \"C:\\Users\\Sandeep\\Desktop\\SignalExtraction v.01\" \"C:\\Users\\Sandeep\\Desktop\\Error-LC\\Method-Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226388a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.StreamPort.device.analyses import PressureCurvesAnalyses\n",
    "\n",
    "path = \"C:/Users/Sandeep/Desktop/Error-LC/Method-Data\"\n",
    "batches = os.listdir(path)\n",
    "batches = [os.path.join(path, file) for file in batches]\n",
    "\n",
    "error_lc_files = []\n",
    "for batch in batches:\n",
    "    batch_files = os.listdir(batch)\n",
    "    batch_files = [os.path.join(batch, file) for file in batch_files if \".D\" in file]\n",
    "    error_lc_files.extend(batch_files)\n",
    "\n",
    "#%store error_lc_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43a5aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyses = PressureCurvesAnalyses(files=error_lc_files)\n",
    "print(\"Number of analyses: \", len(analyses.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ced24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = analyses.get_batches()\n",
    "batch_plot = analyses.plot_batches()\n",
    "batch_plot.show()\n",
    "print(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9e50b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_plot = analyses.plot_batches()\n",
    "batch_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebb0d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.StreamPort.device.methods import PressureCurvesMethodExtractFeaturesNative\n",
    "\n",
    "processor = PressureCurvesMethodExtractFeaturesNative(window_size=4, bins=7) # defaults: (period = 10, window_size = 7, bins = 4, crop = 2)\n",
    "processor.run(analyses)\n",
    "parameters = processor.parameters\n",
    "print(\"Feature extraction parameters: \", parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd72a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = '250620_Mix-1_25x100ng-mL 2025-06-20 09-26-34'\n",
    "batch_indices = analyses.get_batch_indices(batch)\n",
    "fig_sel_method = analyses.plot_batches(batch_indices)\n",
    "\n",
    "fig_sel_method.write_image(\"dev/figures/fig_error_lc_sel_batch.png\", width=1100, height= 350, scale = 3)\n",
    "fig_sel_method.write_image(\"dev/figures/fig_error_lc_sel_batch_half.png\", width=550, height= 350, scale = 3)\n",
    "\n",
    "fig_sel_method.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddc4813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_indices.extend(analyses.get_batch_indices('250703_Mix-1+IS_20x100ng-mL 2025-07-03 09-29-09'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2dcc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_curves_raw = analyses.plot_pressure_curves(batch_indices)\n",
    "\n",
    "fig_curves_raw.update_layout(showlegend=True)\n",
    "\n",
    "for trace in fig_curves_raw.data:\n",
    "    trace.line.color = \"black\"\n",
    "\n",
    "fig_curves_raw.write_image(\"dev/figures/fig_error_lc_curves_raw.png\", width=1100, height= 350, scale = 3)\n",
    "\n",
    "fig_curves_raw.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c7b6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of curves: \", len(batch_indices))\n",
    "print(batch_indices)\n",
    "fig_features=analyses.plot_features(indices = batch_indices)\n",
    "\n",
    "fig_features.update_layout(showlegend=True)\n",
    "for trace in fig_features.data:\n",
    "    trace.line.color = \"black\"\n",
    "\n",
    "fig_features.write_image(\"dev/figures/fig_error_lc_features.png\", width=1100, height= 350, scale = 3)\n",
    "\n",
    "fig_features.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef092e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import datetime\n",
    "#date_threshold = \"2021-08-18\"\n",
    "#date_threshold = datetime.datetime.strptime(date_threshold, \"%Y-%m-%d\")\n",
    "\n",
    "train_indices = []\n",
    "for i in batch_indices:\n",
    "    meta = analyses.get_metadata(i)\n",
    "    batch_position = meta[\"batch_position\"].item()\n",
    "    start_time = meta[\"start_time\"].item()\n",
    "    # if isinstance(start_time, str):\n",
    "    #     start_time = datetime.datetime.fromisoformat(start_time)\n",
    "    if batch_position in [5, 8, 9, 10, 11] or batch_position in range(18, 29):\n",
    "        train_indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7534e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = [i for i in train_indices if i not in [175, 165] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f69daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_train=analyses.plot_pressure_curves(indices = train_indices)\n",
    "fig_train.update_layout(showlegend=True)\n",
    "for trace in fig_train.data:\n",
    "    trace.line.color = \"black\"\n",
    "fig_train.write_image(\"dev/figures/fig_error_lc__train.png\", width=1100, height= 350, scale = 3)\n",
    "fig_train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b112351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices.remove(162)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d37f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = analyses.get_features(train_indices)\n",
    "train_metadata = analyses.get_metadata(train_indices)\n",
    "train_data.to_csv(\"dev/error_lc_train_features.csv\", index=False)\n",
    "train_metadata.to_csv(\"dev/error_lc_train_metadata.csv\", index=False)\n",
    "print(\"Number of training curves: \", len(train_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e980c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_indices  = list(set(batch_indices) - set(train_indices))\n",
    "print(\"Train indices: \", len(train_indices), \" \", train_indices)\n",
    "print(\"Test indices: \", len(rest_indices), \" \", rest_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c462b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "for i in [1, 2, 3, 4]:\n",
    "    test_indices = random.sample(rest_indices, random.randint(4, 5))\n",
    "    print(\"Test set \", i ,  \" indices: \", test_indices)\n",
    "\n",
    "    test_data = analyses.get_features(test_indices)\n",
    "    test_metadata = analyses.get_metadata(test_indices)\n",
    "    test_data.to_csv(f\"dev/error_lc_test{i}_features.csv\", index=False)\n",
    "    test_metadata.to_csv(f\"dev/error_lc_test{i}_metadata.csv\", index=False)\n",
    "\n",
    "    fig_test_curves=analyses.plot_pressure_curves(indices = test_indices)\n",
    "    fig_test_curves.update_layout(showlegend=False)\n",
    "    fig_test_curves.write_image(f\"dev/figures/fig_error_lc_test{i}_curves.png\", width=1000, height= 350, scale = 3)\n",
    "    #fig_test_curves.update_layout(showlegend=True)\n",
    "    #fig_test_curves.show()\n",
    "\n",
    "    fig_test_features=analyses.plot_features(indices = test_indices)\n",
    "    fig_test_features.update_layout(showlegend=False)\n",
    "    fig_test_features.write_image(f\"dev/figures/fig_error_lc_test{i}_features.png\", width=1100, height= 350, scale = 3)\n",
    "    fig_test_features.update_layout(title=f\"Test set {i}\", showlegend=True)\n",
    "    fig_test_features.show()\n",
    "    \n",
    "    fig_test_features_raw = analyses.plot_features_raw(indices = test_indices)\n",
    "    fig_test_features_raw.update_layout(showlegend=False)\n",
    "    fig_test_features_raw.write_image(f\"dev/figures/fig_error_lc_test{i}_features_raw.png\", width=1100, height= 350, scale = 3)\n",
    "    fig_test_features_raw.update_layout(title=f\"Test set {i}\", showlegend=True)\n",
    "    fig_test_features_raw.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8db4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.StreamPort.machine_learning.analyses import MachineLearningAnalyses\n",
    "\n",
    "iso_analyses = MachineLearningAnalyses(variables = train_data, metadata = train_metadata)\n",
    "print(iso_analyses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2079f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.StreamPort.machine_learning.methods import MachineLearningScaleFeaturesScalerSklearn \n",
    "\n",
    "scl = MachineLearningScaleFeaturesScalerSklearn()\n",
    "scaling_parameters = scl.parameters\n",
    "print(\"Scaling parameters: \", scaling_parameters)\n",
    "parameters.update(scaling_parameters)\n",
    "\n",
    "iso_analyses = scl.run(iso_analyses)\n",
    "fig_train_features = iso_analyses.plot_data()\n",
    "fig_train_features.update_layout(title=\"Train set features\")\n",
    "fig_train_features.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607b144c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.StreamPort.machine_learning.methods import MachineLearningMethodIsolationForestSklearn \n",
    "\n",
    "iso = MachineLearningMethodIsolationForestSklearn()\n",
    "iforest_parameters = iso.parameters\n",
    "print(\"Isolation Forest parameters: \", iforest_parameters)\n",
    "parameters.update(iforest_parameters)\n",
    "\n",
    "iso_analyses = iso.run(iso_analyses)\n",
    "fig_train_scores = iso_analyses.plot_scores()\n",
    "fig_train_scores.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5071af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "def set_class_label(test_metadata, outliers_test):\n",
    "    \n",
    "    temp_outliers_test = outliers_test\n",
    "    temp_outliers_test[\"outlier\"] = temp_outliers_test[\"outlier\"].map({True: \"outlier\", False: \"normal\"})\n",
    "    temp_outliers_test[\"class\"] = temp_outliers_test[\"outlier\"]\n",
    "    temp_outliers_test.drop(columns=[\"outlier\"], inplace = True)\n",
    "\n",
    "    classified_test_metadata = pd.concat([test_metadata[\"index\"], temp_outliers_test], axis=1)\n",
    "\n",
    "    return classified_test_metadata\n",
    "\n",
    "#user defined constraints determine that data should be added to the training set if it has been declared an inlier a minimum of x times with a confidence >= y. add_prediction needs to be tweaked \n",
    "# def prepare_to_add(confidence : int = None, classified_normal : int = None):\n",
    "#     #error_lc_test_record holds all the tests conducted. Date is common with the logs of each test : classified samples\n",
    "#     test_record = pd.read_csv(\"dev/error_lc_test_record.csv\")\n",
    "#     tests = [f for f in os.listdir(os.getcwd()) if f.endswith(\".csv\") and test_record[\"date\"].any() in f]\n",
    "#     print(tests)\n",
    "#     search_columns = [\"index\", \"confidence\", \"class\"]\n",
    "#     sample_list = pd.DataFrame()\n",
    "#     if len(test_record.index) > 3:\n",
    "#         for file in tests:\n",
    "#             test = pd.read_csv(file)\n",
    "#             sample_list = pd.concat([sample_list, test[search_columns]])\n",
    "#     else:\n",
    "#         print(\"Not enough evidence of true inliers! You may still add training data using add_prediction()\")\n",
    "#         return\n",
    "#     print(sample_list)\n",
    "    \n",
    "#     \"\"\" FIX this logic       \n",
    "#     # Total appearances of each index\n",
    "#     count_all = sample_list[\"index\"].value_counts().rename(\"total_count\")\n",
    "\n",
    "#     # Appearances where class == \"normal\"\n",
    "#     is_normal = sample_list[sample_list[\"class\"] == \"normal\"]\n",
    "#     count_normal = is_normal[\"index\"].value_counts().rename(\"normal_count\")\n",
    "\n",
    "#     # Normal entries with confidence < threshold\n",
    "#     low_conf_normal = is_normal[is_normal[\"confidence\"] < confidence]\n",
    "#     count_low_conf = low_conf_normal[\"index\"].value_counts().rename(\"conf_amount\")\n",
    "#     \"\"\"\n",
    "#     # Combine all into one DataFrame\n",
    "#     summary = pd.concat([count_all, count_normal, count_low_conf], axis=1).fillna(0).astype(int)\n",
    "#     summary = summary[summary[\"normal_count\"] >= classified_normal]\n",
    "#     return summary\n",
    "\n",
    "# summary = prepare_to_add(70, 3)\n",
    "# print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dad5bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = \"auto\"\n",
    "parameters_df = []\n",
    "for i in [1, 2, 3, 4]:\n",
    "    now = datetime.datetime.now().isoformat()\n",
    "    now = now.replace(\":\", \"-\").replace(\".\", \"-\")\n",
    "\n",
    "    test_data = pd.read_csv(f\"dev/error_lc_test{i}_features.csv\")\n",
    "    test_metadata = pd.read_csv(f\"dev/error_lc_test{i}_metadata.csv\")\n",
    "    iso_analyses.predict(test_data, test_metadata)\n",
    "    outliers_test = iso_analyses.test_prediction_outliers(threshold)\n",
    "    \n",
    "    classified_test_metadata = set_class_label(test_metadata, outliers_test)\n",
    "    classified_test_metadata[\"date\"] = now\n",
    "\n",
    "    print(\"Test set \", i, \": \\n\", test_metadata[\"index\"].tolist()) \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    test_batch_parameters = parameters.copy()\n",
    "    test_set = len(test_metadata)\n",
    "\n",
    "    train_scores = iso_analyses.get_training_scores()\n",
    "    train_set = len(train_scores)\n",
    "\n",
    "    threshold = classified_test_metadata[\"threshold\"].iloc[1]\n",
    "    num_outliers = sum(classified_test_metadata[\"class\"] == \"outlier\")\n",
    "    percent_outliers = (sum(classified_test_metadata[\"class\"] == \"outlier\")/len(classified_test_metadata[\"class\"]))*100\n",
    "\n",
    "    fig_test_scores = iso_analyses.plot_scores(threshold)\n",
    "    fig_test_scores.write_image(f\"dev/figures/fig_error_lc_test{i}_{now}_scores.png\", width=1100, height= 350, scale = 3)\n",
    "    fig_test_scores.update_layout(title=f\"Test set {i}\")\n",
    "    fig_test_scores.show()\n",
    "\n",
    "    fig_test_features = iso_analyses.plot_data()\n",
    "    fig_test_features.write_image(f\"dev/figures/fig_error_lc_test{i}_{now}_features.png\", width=1100, height= 350, scale = 3)\n",
    "    #fig_test_features.show()\n",
    "\n",
    "    #optionally add seen normal curves to train set\n",
    "    #iso_analyses.add_prediction()\n",
    "\n",
    "    if num_outliers < 1:\n",
    "        threshold += 0.5*np.std(train_scores)\n",
    "\n",
    "    test_batch_parameters.update(\n",
    "        {\n",
    "        \"date\" : now,\n",
    "        \"test_batch\" : i,\n",
    "        \"train_set\" : train_set, \n",
    "        \"test_set\" : test_set,\n",
    "        \"threshold\" : threshold,\n",
    "        \"outliers\" : num_outliers,\n",
    "        \"outliers_percent\" : percent_outliers\n",
    "        }\n",
    "    )\n",
    "    parameters_df.append(test_batch_parameters)\n",
    "\n",
    "    classification_record = f\"dev/error_lc_test{i}_{now}_classified_samples.csv\"\n",
    "    if os.path.exists(classification_record):\n",
    "        old_records = pd.read_csv(classification_record)\n",
    "        classified_test_metadata = pd.concat([old_records, classified_test_metadata])\n",
    "        classified_test_metadata.drop_duplicates(subset=[\"index\", \"date\"], keep=\"last\", inplace=True)\n",
    "    classified_test_metadata.to_csv(classification_record, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d086aa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parameters_df = pd.DataFrame(parameters_df)\n",
    "if os.path.exists(\"dev/error_lc_test_record.csv\"):\n",
    "    old_records = pd.read_csv(\"dev/error_lc_test_record.csv\")\n",
    "    parameters_df = pd.concat([old_records, parameters_df])\n",
    "    parameters_df.drop_duplicates(subset=[\"test_batch\", \"date\"], keep=\"last\", inplace=True)\n",
    "    \n",
    "parameters_df.to_csv(\"dev/error_lc_test_record.csv\", index = False)\n",
    "print(\"Workflow parameters: \\n\", parameters_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb3885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "test_record = pd.read_csv(\"dev/error_lc_test_record.csv\") if os.path.exists(\"dev/error_lc_test_record.csv\") else None\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "if test_record is not None:\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=test_record[\"train_set\"],\n",
    "            y=test_record[\"threshold\"],\n",
    "            mode=\"lines+markers\",\n",
    "            name=\"Threshold\",\n",
    "            yaxis=\"y1\",  \n",
    "            hovertemplate=[\n",
    "                \"<br>Threshold: \" + str(test_record[\"threshold\"][i]) +\n",
    "                \"<br>Outliers %: \" + str(test_record[\"outliers_percent\"][i]) \n",
    "                for i in range(len(test_record))\n",
    "            ],\n",
    "            line=dict(color=\"red\", width=2, dash='dash'),\n",
    "            marker=dict(size=8, symbol=\"circle\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=test_record[\"train_set\"],\n",
    "            y=test_record[\"outliers\"],\n",
    "            name=\"Outliers\",\n",
    "            yaxis=\"y2\",\n",
    "            width = 0.05, \n",
    "            marker_color=\"blue\",\n",
    "            hovertemplate=[\n",
    "                \"<br>Train Set: \" + str(test_record[\"train_set\"][i]) +\n",
    "                \"<br>Test Set: \" + str(test_record[\"test_set\"][i]) +\n",
    "                \"<br>Outliers: \" + str(test_record[\"outliers\"][i])\n",
    "                for i in range(len(test_record))\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Threshold and Outliers vs. Training Set Size\",\n",
    "    xaxis=dict(title=\"Number of Training Curves\"),\n",
    "    yaxis=dict(  \n",
    "        title=dict(text=\"Threshold\", font=dict(color=\"red\")),\n",
    "        tickfont=dict(color=\"red\")\n",
    "    ),\n",
    "    yaxis2=dict(  \n",
    "        title=dict(text=\"Number of Outliers\", font=dict(color=\"blue\")),\n",
    "        tickfont=dict(color=\"blue\"),\n",
    "        overlaying=\"y\",\n",
    "        side=\"right\"\n",
    "    ),\n",
    "    bargap = 1, \n",
    "    template=\"simple_white\",\n",
    "    legend=dict(\n",
    "        x=0.5,\n",
    "        y=1.1,\n",
    "        xanchor=\"center\",\n",
    "        yanchor=\"top\",\n",
    "        orientation=\"h\",  \n",
    "        bgcolor=\"rgba(255,255,255,0.5)\", \n",
    "        borderwidth=1  \n",
    "    )\n",
    ")\n",
    "fig.write_image(\"dev/figures/fig_error_lc_threshold_variation.png\", width=1100, height= 350, scale = 3)\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
