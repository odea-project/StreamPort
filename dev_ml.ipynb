{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MachineLearningEngine Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MachineLearningEngine class is builds on the CoreEngine class. The CoreEngine class serves as a parent class engines that focus on data, while the MachineLearningEngine class is for engines that focus on learning from data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.StreamPort.ml.MachineLearningEngine import MachineLearningEngine\n",
    "\n",
    "#Creates an empty MachineLearningEngine object and prints it\n",
    "engine = MachineLearningEngine()\n",
    "engine.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MachineLearningAnalysis Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MachineLearningAnalysis class is builds on the class Analysis. The Analysis class that is used to perform analysis on the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.StreamPort.ml.MachineLearningAnalysis import MachineLearningAnalysis\n",
    "\n",
    "#Creates an empty MachineLearningAnalysis obejct and prints it\n",
    "analysis = MachineLearningAnalysis()\n",
    "analysis.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the CSV File  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method loads the dataset from csv file and create a list of analysis object. Used the data to make a matrix with the analysis names and visualizes the results using a scatter plot.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.StreamPort.ml.MachineLearningEngine import MachineLearningEngine\n",
    "from sklearn.decomposition import PCA \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Creates an empty MachineLearningEngine object and prints it\n",
    "path = 'feature_list.csv'\n",
    "engine = MachineLearningEngine()\n",
    "engine.add_analyses_from_csv(path)\n",
    "\n",
    "engine.print()\n",
    "\n",
    "print(\"Create a list of analysis object and prints it\" )\n",
    "for analysis in engine._analyses:\n",
    "    print(f\"Analysis: {analysis.name}\")\n",
    "    for key, value in analysis.data.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "rownames = engine.get_analyses_names()\n",
    "print(\"Analysename: \", rownames)\n",
    "\n",
    "mat = engine.get_data()\n",
    "mat.index = rownames\n",
    "print(\"Matrix: \\n\", mat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a Principle Conponent Analysis (PCA)\n",
    "\n",
    "The method implements a machine learning engine that perfporms PCA on the dataset and visualizes the results. ProcessingSetting is the parent of MakePCA. The ProcessingSettings used to assemble data processing workflows within the each engine. The subclass MakePCASKL of MakePCA using skitklearn algorithm to perform the PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure of the CSV file: {'number_of_rows': 45, 'number_of_columns': 4445}\n",
      "Structure of the CSV file: {'number_of_rows': 45, 'number_of_columns': 2}\n",
      "\n",
      "MachineLearningEngine \n",
      "  name: None \n",
      "  author: None \n",
      "  path: None \n",
      "  date: 2024-08-10 09:57:42.874897 \n",
      "  analyses: 45 \n",
      "  settings: 0 \n",
      "\n",
      "\n",
      "MachineLearningEngine \n",
      "  name: None \n",
      "  author: None \n",
      "  path: None \n",
      "  date: 2024-08-10 09:57:42.874897 \n",
      "  analyses: 45 \n",
      "  settings: 1 \n",
      "\n",
      "Running workflow with settings: MakeModel\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.StreamPort.ml.MachineLearningEngine import MachineLearningEngine\n",
    "from src.StreamPort.ml.MachineLearningProcessingSettings import  MakeModelPCASKL\n",
    "import webbrowser\n",
    "\n",
    "#Creates an empty MachineLearningEngine object and prints it\n",
    "path = 'feature_list.csv'\n",
    "engine = MachineLearningEngine()\n",
    "engine.add_analyses_from_csv(path)\n",
    "\n",
    "class_path = 'feature_metadata.csv'\n",
    "engine.add_classes_from_csv(class_path)\n",
    "\n",
    "engine.print()\n",
    "#print(engine.get_classes())\n",
    "\n",
    "# !!! make a general data plot\n",
    "engine.plot_data()\n",
    "webbrowser.open('general_data_plot.html')\n",
    "# x axis in the index of the features (i.e., col names)\n",
    "# y axis is the valule for each analysis\n",
    "# color legend is applied for each analysis\n",
    "\n",
    "\n",
    "# Add the ProcessingSettings to the _settings attribute with add settings\n",
    "pca_model = MakeModelPCASKL(n_components = 2, center_data= True)\n",
    "engine.add_settings(pca_model)\n",
    "engine.print()\n",
    "# Create a method in the ML engine to perfom PCA and collect the results\n",
    "engine.run_workflow()\n",
    "# The results are added to the _results atribute of the engine\n",
    "# make a plot method in the ML engine for the PCA results and classes\n",
    "engine.plot_pca()\n",
    "webbrowser.open('pca_scores_plot.html')\n",
    "webbrowser.open('pca_loadings_plot.html')\n",
    "# make a loadings plot after confirming the scores plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a Density-Based Spatial Clustering of Application with Noise (DBSCAN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.StreamPort.ml.MachineLearningEngine import MachineLearningEngine\n",
    "from src.StreamPort.ml.MachineLearningProcessingSettings import  MakeModelDBSCANSKL\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import plotly.express as px\n",
    "\n",
    "# Creates an empty MachineLearningEngine object and prints it\n",
    "path = 'feature_list.csv'\n",
    "engine = MachineLearningEngine()\n",
    "engine.add_analyses_from_csv(path)\n",
    "\n",
    "class_path = 'feature_metadata.csv'\n",
    "engine.add_classes_from_csv(class_path)\n",
    "\n",
    "engine.print()\n",
    "\n",
    "data = engine.get_data()\n",
    "mean = np.mean(data, axis=0)\n",
    "data = data - mean\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "data_2d = pca.fit_transform(data)\n",
    "print(\"Reduced data shape:\", data_2d.shape)\n",
    "\n",
    "# Visualize the data\n",
    "plt.scatter(data_2d[:, 0], data_2d[:, 1])\n",
    "plt.title('Data Visualization')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()\n",
    "\n",
    "# Create a k-distance plot\n",
    "k = 5  # Choose k based on min_samples\n",
    "neighbors = NearestNeighbors(n_neighbors=k)\n",
    "neighbors_fit = neighbors.fit(data)\n",
    "distances, indices = neighbors_fit.kneighbors(data)\n",
    "distances = np.sort(distances[:, k-1], axis=0)\n",
    "\n",
    "plt.plot(distances)\n",
    "plt.title('K-Distance Plot')\n",
    "plt.xlabel('Points sorted by distance')\n",
    "plt.ylabel('Distance to {}-th nearest neighbor'.format(k))\n",
    "plt.show()\n",
    "\n",
    "# Experiment with DBSCAN parameters\n",
    "eps = 1.5E6  # Adjust based on the k-distance plot\n",
    "min_samples = 3  # Adjust based on your data\n",
    "\n",
    "dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "dbscan.fit(data_2d)\n",
    "\n",
    "labels = dbscan.labels_\n",
    "\n",
    "# Analyze the clusters\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "print(\"Estimated number of noise points: %d\" % n_noise_)\n",
    "\n",
    "# Create a DataFrame for Plotly\n",
    "df = pd.DataFrame(data_2d, columns=['PC1', 'PC2'])\n",
    "df['Cluster'] = labels.astype(str)  # Convert to string for categorical coloring\n",
    "\n",
    "# Plot the results using Plotly\n",
    "fig = px.scatter(df, x='PC1', y='PC2', color='Cluster', title='DBSCAN Clustering Results',\n",
    "                 labels={'PC1': 'Principal Component 1', 'PC2': 'Principal Component 2'})\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
