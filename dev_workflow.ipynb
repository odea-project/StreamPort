{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de013450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute related notebooks within the scope of the current one to use their variables without the need for individual imports or file creation\n",
    "#%run dev_pressure_curves.ipynb dev_machine_learning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57f172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, we import pressure curve files/object to run through a simple workflow. %store -[OPTION] var to -r : retrieve, -d : delete, -z : clear all  \n",
    "%store -r pc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36557f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_plot = pc.plot_methods()\n",
    "methods_plot.show()\n",
    "\n",
    "methods = pc.get_methods()\n",
    "print(\"Methods: \", methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c89051",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pc.get_method_indices('SAA_411_Pac.M')\n",
    "pac_plots = pc.plot_batches(indices)\n",
    "pac_plots.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ed2e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.StreamPort.device.methods import PressureCurvesMethodExtractFeaturesNative\n",
    "\n",
    "processor = PressureCurvesMethodExtractFeaturesNative(period=10, bins=6, window_size=7)\n",
    "pc = processor.run(pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903195ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = [batch for batch in pc.get_batches() if \"Pac\" in batch]\n",
    "print(\"Batches: \", batches)\n",
    "\n",
    "batches.sort()\n",
    "print(\"Sorted by date: \", batches)\n",
    "\n",
    "tests = batches[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2096062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test batch dates: \", tests) # used to get train data, then discarded and test sets iteratively selected by increasing batch date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa202170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training set\n",
    "first_test_group = tests[0]\n",
    "print(\"First test group date: \", first_test_group)\n",
    "\n",
    "first_test = first_test_group.split(\" \")[-2:]\n",
    "first_test = \" \".join(first_test)\n",
    "first_test = first_test.replace(\":\", \"-\")\n",
    "\n",
    "date_threshold_min = first_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5ec7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = []\n",
    "for i in indices:\n",
    "    meta = pc.get_metadata(i)\n",
    "    batch_position = meta[\"batch_position\"].item()\n",
    "    start_time = meta[\"start_time\"].item()\n",
    "    if isinstance(start_time, str):\n",
    "        start_time = start_time.replace(\":\", \"-\")\n",
    "    else:\n",
    "        start_time = start_time.strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "    if batch_position > 5 and start_time < date_threshold_min:\n",
    "        train_indices.append(i)\n",
    "\n",
    "train_data = pc.get_features(train_indices)\n",
    "train_metadata = pc.get_metadata(train_indices)\n",
    "train_data.to_csv(\"dev/workflow_train_features.csv\", index=False) # test data files will include batch date\n",
    "train_metadata.to_csv(\"dev/workflow_train_metadata.csv\", index=False)\n",
    "\n",
    "train_size = len(train_indices)\n",
    "print(\"Number of training curves: \", train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eb329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_train=pc.plot_pressure_curves(train_indices)\n",
    "fig_train.update_layout(showlegend=False)\n",
    "fig_train.show()\n",
    "#train_indices.extend([239, 245, 266, 117])# 117 is interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b63356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_train_features = pc.plot_features(train_indices)\n",
    "fig_train_features.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda06565",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe() # maybe this can be fed to model to guide feature selection for splits based on importance. Increase weight of less-impactful statistical features like area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53615ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.StreamPort.machine_learning.analyses import MachineLearningAnalyses\n",
    "\n",
    "ml_ana = MachineLearningAnalyses(variables = train_data, metadata = train_metadata)\n",
    "print(ml_ana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f80a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.StreamPort.machine_learning.methods import MachineLearningScaleFeaturesScalerSklearn\n",
    "\n",
    "scaler = MachineLearningScaleFeaturesScalerSklearn(scaler_type = \"StandardScaler\")\n",
    "ml_ana = scaler.run(ml_ana)\n",
    "\n",
    "fig_train_features = ml_ana.plot_data()\n",
    "fig_train_features.update_layout(title=\"Train set features\")\n",
    "fig_train_features.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482ec6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src.StreamPort.machine_learning.methods import MachineLearningMethodIsolationForestSklearn\n",
    "\n",
    "iforest = MachineLearningMethodIsolationForestSklearn()\n",
    "\n",
    "ml_ana = iforest.run(ml_ana)\n",
    "\n",
    "\n",
    "ml_ana.train()\n",
    "fig_train_scores = ml_ana.plot_scores()\n",
    "fig_train_scores.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa9cf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new tests sorted by date\n",
    "tests = {}\n",
    "for batch in batches:\n",
    "    batch_date = batch.split(\" \")[-2 : ]\n",
    "    batch_date = \" \".join(batch_date)\n",
    "\n",
    "    if batch_date >= date_threshold_min: # search and collect test samples\n",
    "        date_threshold_min = batch_date \n",
    "        \n",
    "        test_indices = pc.get_batch_indices(batch)\n",
    "        test_size = len(test_indices)\n",
    "\n",
    "        for i in range(test_size):\n",
    "            tests[f\"{batch_date}_{i+1}\"] = test_indices[i]\n",
    "            \n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f02456",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = list(tests.keys())\n",
    "print(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca68ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for date in dates[:1]:\n",
    "date = dates[0]\n",
    "\n",
    "test_data = pc.get_features(tests[date])\n",
    "test_metadata = pc.get_metadata(tests[date])\n",
    "\n",
    "print(f\"Test {date}: index:\", tests[date])\n",
    "train_indices.append(tests[date])\n",
    "\n",
    "fig_test_features = pc.plot_features(train_indices, normalize=False)\n",
    "fig_test_features.show()\n",
    "\n",
    "fig_test_features_raw = pc.plot_features_raw(train_indices)\n",
    "fig_test_features_raw.update_layout(showlegend=False)\n",
    "fig_test_features_raw.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc032817",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_ana.predict(test_data, test_metadata)\n",
    "\n",
    "outliers = ml_ana.test_prediction_outliers() # defaults: n_tests = 1, show_scores = False\n",
    "print(outliers)\n",
    "\n",
    "fig_test_curves = pc.plot_pressure_curves(test_metadata[\"index\"].tolist())\n",
    "fig_test_curves.show()\n",
    "\n",
    "fig_test_scores = ml_ana.plot_scores()\n",
    "fig_test_scores.update_layout(title=f\"Test set {date} final run\")\n",
    "fig_test_scores.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afb43de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confidence_plot = evaluator.plot_confidences()\n",
    "confidence_plot = ml_ana.plot_confidences()\n",
    "confidence_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133ea6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "test_data.drop(columns=\"runtime\", inplace=True)\n",
    "data = pd.concat([test_metadata, test_data], axis=1)\n",
    "\n",
    "if outliers[\"class\"].iloc[0] == \"outlier\":\n",
    "    outlier_data = data\n",
    "\n",
    "    if os.path.exists(\"dev/outliers.csv\"):\n",
    "        outliers_file = pd.read_csv(\"dev/outliers.csv\")\n",
    "        outliers_file = pd.concat([outliers_file, outlier_data], axis = 0)\n",
    "        outliers_file.drop_duplicates(subset=\"index\", inplace = True, ignore_index=True)\n",
    "        outliers_file.to_csv(\"dev/outliers.csv\", index=False)\n",
    "    \n",
    "    else:\n",
    "        outlier_data.to_csv(\"dev/outliers.csv\", index=False)\n",
    "\n",
    "else:\n",
    "\n",
    "    if os.path.exists(\"dev/normals.csv\"):\n",
    "        normals_file = pd.read_csv(\"dev/normals.csv\")\n",
    "\n",
    "        normals_file = pd.concat([normals_file, data], axis = 0)\n",
    "        normals_file.drop_duplicates(subset=\"index\", inplace=True, ignore_index=True)\n",
    "        normals_file.to_csv(\"dev/normals.csv\", index=False)\n",
    "    \n",
    "    else:\n",
    "        data.to_csv(\"dev/normals.csv\", index=False)\n",
    "\n",
    "ml_ana.add_prediction() # add_data already calls self.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0f8a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold_plot = evaluator.plot_threshold_variation()\n",
    "threshold_plot = ml_ana.plot_threshold_variation()\n",
    "threshold_plot.show()\n",
    "#threshold_plot.write_image(\"dev/figures/fig_threshold_variation_serialized_tests.png\", width=1100, height= 350, scale = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fde3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_time_plot = evaluator.plot_train_time()\n",
    "train_time_plot = ml_ana.plot_train_time()\n",
    "train_time_plot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
