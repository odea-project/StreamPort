{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8166331f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sandeep\\Desktop\\StreamPort\\sp\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from src.StreamPort.machine_learning.methods import MachineLearningEvaluateModelStabilityNative\n",
    "\n",
    "rest_indices = 20\n",
    "test_indices = 4\n",
    "\n",
    "path_to_test_records = \"dev/error_lc_test_record.csv\"\n",
    "\n",
    "test_record = pd.read_csv(path_to_test_records) if os.path.exists(path_to_test_records) else None\n",
    "test_record = test_record.sort_values(\"date\") if test_record is not None else None\n",
    "if test_record is not None and len(test_record) > rest_indices//test_indices:\n",
    "    result_logs = []\n",
    "    for date in test_record[\"date\"]:\n",
    "        result_logs.append(f\"dev/error_lc_test_{date}_classified_samples.csv\") if os.path.exists(f\"dev/error_lc_test_{date}_classified_samples.csv\") else print(f\"No records for {date}\")\n",
    "else:\n",
    "    print(\"Not enough evidence of true inliers! Please run more tests for more data\")\n",
    "\n",
    "summary = pd.DataFrame()\n",
    "for log in result_logs:\n",
    "    log = pd.read_csv(log)\n",
    "    summary = pd.concat([summary, log], ignore_index=True)\n",
    "summary = summary.sort_values(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025479eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance Summary:      index  threshold     score  confidence    class  \\\n",
      "0     158  -0.053316 -0.097339        1.83  outlier   \n",
      "1     158  -0.066785 -0.078174        1.17  outlier   \n",
      "2     158  -0.066785 -0.078174        1.17  outlier   \n",
      "3     158  -0.066785 -0.078174        1.17  outlier   \n",
      "4     158  -0.046520 -0.078519        1.69  outlier   \n",
      "..    ...        ...       ...         ...      ...   \n",
      "68    190  -0.056991 -0.043293        0.76   normal   \n",
      "69    190  -0.053316 -0.054654        1.03  outlier   \n",
      "70    190  -0.066785 -0.040508        0.61   normal   \n",
      "71    190  -0.066785 -0.040508        0.61   normal   \n",
      "72    190  -0.046520 -0.043293        0.93   normal   \n",
      "\n",
      "                          date class_true  stability_score  \n",
      "0   2025-07-23 12-34-26-872389    outlier         0.905672  \n",
      "1   2025-07-23 14-49-28-169722                    0.905672  \n",
      "2   2025-07-23 14-49-20-912694                    0.905672  \n",
      "3   2025-07-23 15-36-48-666559                    0.905672  \n",
      "4   2025-07-23 16-34-58-573933                    0.905672  \n",
      "..                         ...        ...              ...  \n",
      "68  2025-07-23 16-34-47-475292     normal         0.813400  \n",
      "69  2025-07-23 12-34-32-478978                    0.813400  \n",
      "70  2025-07-23 14-49-35-410842                    0.813400  \n",
      "71  2025-07-23 14-49-42-662975                    0.813400  \n",
      "72  2025-07-23 16-35-04-244376                    0.813400  \n",
      "\n",
      "[73 rows x 8 columns]\n",
      "True classes:        class_true majority_class  confidence_consistency\n",
      "index                                                  \n",
      "158      outlier        outlier                0.811345\n",
      "159      not set        outlier                0.915219\n",
      "160      outlier        outlier                0.845011\n",
      "161      outlier        outlier                0.762037\n",
      "162      not set        outlier                1.000000\n",
      "163      outlier        outlier                0.942529\n",
      "164      outlier        outlier                0.826712\n",
      "165      not set        outlier                0.833900\n",
      "169      not set         normal                0.090909\n",
      "170      outlier        outlier                0.835444\n",
      "171      outlier        outlier                0.895936\n",
      "172      not set         normal                0.809256\n",
      "173      not set        outlier                0.897706\n",
      "174       normal         normal                0.988827\n",
      "175      not set         normal                0.878234\n",
      "186       normal         normal                0.623543\n",
      "187       normal         normal                0.854612\n",
      "188      not set         normal                0.090909\n",
      "189       normal         normal                0.707006\n",
      "190       normal         normal                0.826801\n",
      "Model stability score:  0.8512555719597781\n"
     ]
    }
   ],
   "source": [
    "model_eval = MachineLearningEvaluateModelStabilityNative(test_records=summary)\n",
    "true_classes, stability_score = model_eval.run()\n",
    "print(\"True classes: \", true_classes)\n",
    "print(\"Model stability score: \", stability_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d7c712",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (true_classes[\"class_true\"] == \"not_set\").any():\n",
    "    print(\"Classification Complete\")\n",
    "else:\n",
    "    print(\"Some samples are unverified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304259e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#models have internal stochastic variability due to the way in which they classify/regress. Compare detection results across tests with default parameters to find stability in performance\n",
    "def get_model_stability(confidence_buffer : float = 0.1, times_classified : int = 2):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #if non-deterministic model, data should be added to the training set if it has been declared an inlier a minimum of x times with a confidence <= y. add_prediction needs to be tweaked(?) \n",
    "    def get_true_classes(group):\n",
    "        outlier_count = ((group['class'] == 'outlier') & (group['confidence'] > 1 + confidence_buffer)).sum() #1 confidence = threshold value. anomaly > 1, normal < 1\n",
    "        inlier_count = ((group['class'] == 'normal') & (group['confidence'] < 1 - confidence_buffer)).sum() #values between 0.9 and 1.1 taken as a buffer zone of ambiguous detection accuracy\n",
    "\n",
    "        if outlier_count > times_classified and outlier_count > inlier_count:\n",
    "            return \"outlier\"\n",
    "        elif inlier_count > times_classified and inlier_count > outlier_count:\n",
    "            return \"normal\"\n",
    "        else:\n",
    "            return \"not set\"\n",
    "\n",
    "    class_results = summary.groupby('index').apply(get_true_classes, include_groups=False).reset_index(name='class_true') ####1####\n",
    "\n",
    "    summary = summary.merge(class_results, on='index', how='left')\n",
    "\n",
    "    first_occurrence = ~summary.duplicated(subset='index')\n",
    "\n",
    "    summary.loc[~first_occurrence, 'class_true'] = \"\"  \n",
    "    \n",
    "    #calculate agreement between results per test index\n",
    "    label_counts = summary.groupby(['index', 'class']).size().unstack(fill_value=0)\n",
    "    max_counts = label_counts.max(axis=1)\n",
    "    total_counts = label_counts.sum(axis=1)\n",
    "    agreement_ratio = max_counts / total_counts #ranges from 0.5 (flip-flopping) to 1.0 (always same label)\n",
    "\n",
    "    #find majority class per index (\"normal\" or \"outlier\")\n",
    "    majority_class = label_counts.idxmax(axis=1) ####2####\n",
    "\n",
    "    #calculate coefficient of variation (cv = std/mean) of confidence for majority class per index\n",
    "    def get_confidence_variation(group):\n",
    "        majority = majority_class.loc[group.name]\n",
    "        confidence_values = group.loc[group['class'] == majority, 'confidence']\n",
    "        if len(confidence_values) == 0:\n",
    "            return np.nan  #no data for majority class\n",
    "        mean_confidence = confidence_values.mean()\n",
    "        std_confidence = confidence_values.std()\n",
    "        if mean_confidence == 0 or pd.isna(mean_confidence):\n",
    "            return np.nan\n",
    "        return std_confidence / mean_confidence\n",
    "    \n",
    "    confidence_variation = summary.groupby('index').apply(get_confidence_variation, include_groups=False)\n",
    "\n",
    "    #replace any NaN with a large number to simulate instability\n",
    "    confidence_variation = confidence_variation.fillna(10)\n",
    "\n",
    "    #convert cv to a consistency score: higher cv means lower consistency ####3####\n",
    "    confidence_consistency = 1 / (1 + confidence_variation) #consistency = 1 / (1 + cv) to bound between 0 and 1, ~1 means stable(low variation), ~0 means unstable\n",
    "\n",
    "    #combined stability score (average of agreement and confidence consistency)\n",
    "    combined_stability = (agreement_ratio + confidence_consistency) / 2\n",
    "\n",
    "    true_classes = pd.concat(\n",
    "                                [\n",
    "                                    class_results.set_index(\"index\"), \n",
    "                                    majority_class.rename(\"majority_class\"), \n",
    "                                    confidence_consistency.rename(\"classification_consistency\")\n",
    "                                ], \n",
    "                                axis = 1\n",
    "                            )\n",
    "    \n",
    "    true_classes[\"confidence\"] = true_classes[\"classification_consistency\"].apply(lambda x: \"high\" if x >= 0.8 else \"mid\" if x > 0.65 and x < 0.8 else \"low\")\n",
    "    print(\"True classes: \", true_classes)\n",
    "\n",
    "    stability_df = combined_stability.reset_index(name='stability_score')\n",
    "    summary = summary.merge(stability_df, on='index', how='left')\n",
    "\n",
    "    return (summary, combined_stability.mean())\n",
    "\n",
    "# Usage \n",
    "summary_with_stability = get_model_stability()\n",
    "#print(f\"Overall model stability score: {overall_stability_score}\")\n",
    "print(\"Stability summary: \", summary_with_stability[0].head(), \"\\nModel stability: \", summary_with_stability[1]) if summary_with_stability is not None else print(\"No results yet.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
